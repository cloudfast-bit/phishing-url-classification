{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymEk-woRVIAT"
   },
   "source": [
    "# Build CNN For Comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eghAwvsyQVz_"
   },
   "outputs": [],
   "source": [
    "#Copyright 2019, Seokjun Bu, Softcomputing LAB all rights reserved.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Reshape, Conv2D, Dense, MaxPool2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4273,
     "status": "ok",
     "timestamp": 1583241683289,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "Qal0l12VQ4hs",
    "outputId": "b6d7269b-5923-44de-fc06-118cc1ea6ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Fi9L2q3Q62K"
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/My Drive/test_colab/dataset_2_char_cat_45000_15000_140.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 151923,
     "status": "ok",
     "timestamp": 1583241830950,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "iIsKMKpfRDkl",
    "outputId": "85769336-46f0-49a9-916a-91e2d11a9274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 14000) (42000,)\n",
      "(18000, 14000) (18000,)\n"
     ]
    }
   ],
   "source": [
    "# Train, Test Split\n",
    "X, Y = data[:, 1:], data[:, 0]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, shuffle=True, random_state=11)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPGR2YzOSgOU"
   },
   "outputs": [],
   "source": [
    "Y_train_cnn, Y_test_cnn = to_categorical(Y_train), to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1583242024722,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "VRMZ5R_HUWLE",
    "outputId": "8e36d9cc-e93d-4f32-9600-ac36ea731250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 14000)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 100, 140, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 140, 32)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 50, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 70, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 25, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 56000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 224004    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 232,430\n",
      "Trainable params: 232,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_input = Input((X_train.shape[1],))\n",
    "H = Reshape((100, 140, 1))(cnn_input)\n",
    "\n",
    "H = Conv2D(filters=32, kernel_size=(2,2), padding=\"same\", activation='relu')(H)\n",
    "H = MaxPool2D((2, 2))(H)\n",
    "\n",
    "H = Conv2D(filters=64, kernel_size=(2,2), padding=\"same\", activation='relu')(H)\n",
    "H = MaxPool2D((2, 2))(H)\n",
    "\n",
    "H = Flatten()(H)\n",
    "H = Dense(4, activation='relu')(H)\n",
    "\n",
    "cnn_output = Dense(2, activation = 'softmax')(H)\n",
    "cnn_model = Model(cnn_input, cnn_output)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 591912,
     "status": "ok",
     "timestamp": 1583243032388,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "vj4bldbmWHX1",
    "outputId": "bba9b34f-3641-42a7-e0fe-5482b4f12780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/500\n",
      "33600/33600 [==============================] - 9s 272us/step - loss: 0.4433 - acc: 0.8131 - val_loss: 0.3628 - val_acc: 0.8424\n",
      "Epoch 2/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.3214 - acc: 0.8605 - val_loss: 0.2822 - val_acc: 0.8806\n",
      "Epoch 3/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.2658 - acc: 0.8851 - val_loss: 0.2506 - val_acc: 0.8956\n",
      "Epoch 4/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.2410 - acc: 0.8975 - val_loss: 0.2330 - val_acc: 0.9037\n",
      "Epoch 5/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.2248 - acc: 0.9059 - val_loss: 0.2240 - val_acc: 0.9075\n",
      "Epoch 6/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.2129 - acc: 0.9118 - val_loss: 0.2122 - val_acc: 0.9139\n",
      "Epoch 7/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.2041 - acc: 0.9166 - val_loss: 0.2041 - val_acc: 0.9182\n",
      "Epoch 8/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1967 - acc: 0.9199 - val_loss: 0.1999 - val_acc: 0.9217\n",
      "Epoch 9/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1910 - acc: 0.9238 - val_loss: 0.1940 - val_acc: 0.9225\n",
      "Epoch 10/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1860 - acc: 0.9258 - val_loss: 0.1904 - val_acc: 0.9239\n",
      "Epoch 11/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.1813 - acc: 0.9282 - val_loss: 0.1872 - val_acc: 0.9255\n",
      "Epoch 12/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1797 - acc: 0.9287 - val_loss: 0.1850 - val_acc: 0.9265\n",
      "Epoch 13/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1748 - acc: 0.9315 - val_loss: 0.1871 - val_acc: 0.9270\n",
      "Epoch 14/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1723 - acc: 0.9329 - val_loss: 0.1806 - val_acc: 0.9276\n",
      "Epoch 15/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1697 - acc: 0.9341 - val_loss: 0.1788 - val_acc: 0.9288\n",
      "Epoch 16/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1669 - acc: 0.9352 - val_loss: 0.1779 - val_acc: 0.9285\n",
      "Epoch 17/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1648 - acc: 0.9362 - val_loss: 0.1761 - val_acc: 0.9302\n",
      "Epoch 18/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1630 - acc: 0.9365 - val_loss: 0.1777 - val_acc: 0.9274\n",
      "Epoch 19/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1611 - acc: 0.9367 - val_loss: 0.1753 - val_acc: 0.9289\n",
      "Epoch 20/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1612 - acc: 0.9372 - val_loss: 0.1727 - val_acc: 0.9319\n",
      "Epoch 21/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1581 - acc: 0.9385 - val_loss: 0.1742 - val_acc: 0.9308\n",
      "Epoch 22/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1566 - acc: 0.9402 - val_loss: 0.1789 - val_acc: 0.9281\n",
      "Epoch 23/500\n",
      "33600/33600 [==============================] - 8s 243us/step - loss: 0.1558 - acc: 0.9396 - val_loss: 0.1707 - val_acc: 0.9325\n",
      "Epoch 24/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1530 - acc: 0.9416 - val_loss: 0.1705 - val_acc: 0.9330\n",
      "Epoch 25/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1529 - acc: 0.9411 - val_loss: 0.1708 - val_acc: 0.9331\n",
      "Epoch 26/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1519 - acc: 0.9413 - val_loss: 0.1710 - val_acc: 0.9321\n",
      "Epoch 27/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.1502 - acc: 0.9423 - val_loss: 0.1758 - val_acc: 0.9290\n",
      "Epoch 28/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1491 - acc: 0.9428 - val_loss: 0.1696 - val_acc: 0.9349\n",
      "Epoch 29/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1472 - acc: 0.9442 - val_loss: 0.1694 - val_acc: 0.9335\n",
      "Epoch 30/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1460 - acc: 0.9442 - val_loss: 0.1678 - val_acc: 0.9346\n",
      "Epoch 31/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1453 - acc: 0.9451 - val_loss: 0.1666 - val_acc: 0.9357\n",
      "Epoch 32/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1440 - acc: 0.9460 - val_loss: 0.1674 - val_acc: 0.9350\n",
      "Epoch 33/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1432 - acc: 0.9457 - val_loss: 0.1704 - val_acc: 0.9317\n",
      "Epoch 34/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1430 - acc: 0.9451 - val_loss: 0.1673 - val_acc: 0.9333\n",
      "Epoch 35/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1417 - acc: 0.9469 - val_loss: 0.1656 - val_acc: 0.9361\n",
      "Epoch 36/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1404 - acc: 0.9471 - val_loss: 0.1657 - val_acc: 0.9367\n",
      "Epoch 37/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1403 - acc: 0.9473 - val_loss: 0.1701 - val_acc: 0.9326\n",
      "Epoch 38/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1389 - acc: 0.9476 - val_loss: 0.1652 - val_acc: 0.9371\n",
      "Epoch 39/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1383 - acc: 0.9481 - val_loss: 0.1652 - val_acc: 0.9364\n",
      "Epoch 40/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1390 - acc: 0.9473 - val_loss: 0.1652 - val_acc: 0.9369\n",
      "Epoch 41/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1364 - acc: 0.9487 - val_loss: 0.1682 - val_acc: 0.9335\n",
      "Epoch 42/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1359 - acc: 0.9488 - val_loss: 0.1650 - val_acc: 0.9361\n",
      "Epoch 43/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1353 - acc: 0.9502 - val_loss: 0.1645 - val_acc: 0.9377\n",
      "Epoch 44/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1344 - acc: 0.9496 - val_loss: 0.1667 - val_acc: 0.9343\n",
      "Epoch 45/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1341 - acc: 0.9504 - val_loss: 0.1643 - val_acc: 0.9362\n",
      "Epoch 46/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1325 - acc: 0.9504 - val_loss: 0.1638 - val_acc: 0.9386\n",
      "Epoch 47/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1318 - acc: 0.9511 - val_loss: 0.1674 - val_acc: 0.9338\n",
      "Epoch 48/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1316 - acc: 0.9512 - val_loss: 0.1663 - val_acc: 0.9382\n",
      "Epoch 49/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1308 - acc: 0.9515 - val_loss: 0.1661 - val_acc: 0.9331\n",
      "Epoch 50/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1302 - acc: 0.9520 - val_loss: 0.1635 - val_acc: 0.9375\n",
      "Epoch 51/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1303 - acc: 0.9515 - val_loss: 0.1636 - val_acc: 0.9374\n",
      "Epoch 52/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1286 - acc: 0.9523 - val_loss: 0.1627 - val_acc: 0.9394\n",
      "Epoch 53/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1299 - acc: 0.9513 - val_loss: 0.1631 - val_acc: 0.9374\n",
      "Epoch 54/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1273 - acc: 0.9534 - val_loss: 0.1626 - val_acc: 0.9379\n",
      "Epoch 55/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1275 - acc: 0.9525 - val_loss: 0.1639 - val_acc: 0.9373\n",
      "Epoch 56/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1261 - acc: 0.9537 - val_loss: 0.1625 - val_acc: 0.9387\n",
      "Epoch 57/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1251 - acc: 0.9536 - val_loss: 0.1637 - val_acc: 0.9381\n",
      "Epoch 58/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1258 - acc: 0.9540 - val_loss: 0.1628 - val_acc: 0.9382\n",
      "Epoch 59/500\n",
      "33600/33600 [==============================] - 8s 242us/step - loss: 0.1254 - acc: 0.9531 - val_loss: 0.1619 - val_acc: 0.9389\n",
      "Epoch 60/500\n",
      "33600/33600 [==============================] - 8s 242us/step - loss: 0.1246 - acc: 0.9547 - val_loss: 0.1667 - val_acc: 0.9340\n",
      "Epoch 61/500\n",
      "33600/33600 [==============================] - 8s 242us/step - loss: 0.1237 - acc: 0.9548 - val_loss: 0.1627 - val_acc: 0.9386\n",
      "Epoch 62/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1223 - acc: 0.9546 - val_loss: 0.1621 - val_acc: 0.9388\n",
      "Epoch 63/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1220 - acc: 0.9555 - val_loss: 0.1617 - val_acc: 0.9388\n",
      "Epoch 64/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1213 - acc: 0.9554 - val_loss: 0.1618 - val_acc: 0.9398\n",
      "Epoch 65/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1208 - acc: 0.9562 - val_loss: 0.1624 - val_acc: 0.9389\n",
      "Epoch 66/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1199 - acc: 0.9557 - val_loss: 0.1630 - val_acc: 0.9360\n",
      "Epoch 67/500\n",
      "33600/33600 [==============================] - 8s 241us/step - loss: 0.1197 - acc: 0.9556 - val_loss: 0.1647 - val_acc: 0.9355\n",
      "Epoch 68/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1192 - acc: 0.9558 - val_loss: 0.1624 - val_acc: 0.9399\n",
      "Epoch 69/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1184 - acc: 0.9571 - val_loss: 0.1622 - val_acc: 0.9377\n",
      "Epoch 70/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1183 - acc: 0.9562 - val_loss: 0.1694 - val_acc: 0.9338\n",
      "Epoch 71/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1176 - acc: 0.9566 - val_loss: 0.1617 - val_acc: 0.9386\n",
      "Epoch 72/500\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.1169 - acc: 0.9571 - val_loss: 0.1650 - val_acc: 0.9354\n",
      "Epoch 73/500\n",
      "33600/33600 [==============================] - 8s 239us/step - loss: 0.1167 - acc: 0.9573 - val_loss: 0.1618 - val_acc: 0.9385\n",
      "CPU times: user 6min 12s, sys: 1min 47s, total: 8min\n",
      "Wall time: 9min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "adam = Adam(lr = 1e-04)\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=10, restore_best_weights=True)\n",
    "history = cnn_model.fit(X_train, Y_train_cnn, validation_split=0.2, \n",
    "                        epochs=500, batch_size=512, shuffle=True, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6854,
     "status": "ok",
     "timestamp": 1583243206530,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "JcnIJqqMVFYA",
    "outputId": "989e0064-e1b0-4f02-d9b8-bf2ab9b9141a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.95      0.98      0.96     13546\n",
      "     class 1       0.93      0.84      0.88      4454\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     18000\n",
      "   macro avg       0.94      0.91      0.92     18000\n",
      "weighted avg       0.94      0.94      0.94     18000\n",
      " samples avg       0.94      0.94      0.94     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_model = cnn_model.predict(X_test.astype(\"float\"))\n",
    "y_pred = np.where(y_pred_model > 0.5, 1, 0)\n",
    "print(classification_report(Y_test_cnn, y_pred, target_names=['class 0', 'class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZZ_JF-iYRu1"
   },
   "outputs": [],
   "source": [
    "def func2():\n",
    "  cnn_input = Input((X_train.shape[1],))\n",
    "  H = Reshape((100, 140, 1))(cnn_input)\n",
    "\n",
    "  H = Conv2D(filters=32, kernel_size=(2, 2), padding='same', activation='relu')(H)\n",
    "  H = MaxPool2D((2,2))(H)\n",
    "\n",
    "  H = Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu')(H)\n",
    "  H = MaxPool2D((2,2))(H)\n",
    "  \n",
    "  H = Flatten()(H)\n",
    "  H = Dense(4, activation = 'relu')(H)\n",
    "\n",
    "  cnn_output = Dense(2, activation = 'softmax')(H)\n",
    "\n",
    "  cnn_model = Model(cnn_input,cnn_output)\n",
    "  \n",
    "  cnn_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04OMZnNkpnyX"
   },
   "outputs": [],
   "source": [
    "cnn = KerasClassifier(build_fn=func2, epochs=10, batch_size=10, verbose=0)\n",
    "recall_cnn = cross_val_score(cnn, X_train, Y_train, cv=10, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1583246199234,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "FdFBjMYLptJY",
    "outputId": "76c5f811-2650-4dd8-abd5-b3d437d99bcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87546816, 0.82075472, 0.91468254, 0.89468691, 0.89258555,\n",
       "       0.86363636, 0.        , 0.89126394, 0.89878163, 0.89514563])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9278DSW08ZV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMQlQdaWmpkaSeTrEt4X+T1",
   "machine_shape": "hm",
   "name": "Build CNN.ipynb ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
