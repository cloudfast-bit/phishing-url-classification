{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./url_0.csv' does not exist: b'./url_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-76880f91f301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbenign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./url_0.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m44999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mphishing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./url_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./url_0.csv' does not exist: b'./url_0.csv'"
     ]
    }
   ],
   "source": [
    "benign = pd.read_csv('./url_0.csv').sample(n = 44999, random_state = 2019)\n",
    "phishing = pd.read_csv('./url_1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = pd.DataFrame(benign)\n",
    "benign = pd.DataFrame({'url' : benign['http://www.liquidgeneration.com/'], 'cat' : benign.Adult})\n",
    "benign = benign.append(pd.Series(['http://www.liquidgeneration.com/','Adult'],index=benign.columns),ignore_index=True)\n",
    "phishing = pd.DataFrame(phishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 2), (15261, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign.shape, phishing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "benign = benign.drop(columns = ['cat'])\n",
    "phishing = phishing.drop(columns = ['phish_id','submission_time','verified','phish_detail_url',\n",
    "                                  'verification_time','online','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign['label'] = 0\n",
    "phishing['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([benign,phishing]).reset_index(drop = 'True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Eng'ring\n",
    " - Digit Count of URL\n",
    " - URL 길이\n",
    " - Checking URL is Typosquatted or not (google.com --> goggle.com)\n",
    " - Subdomain 개수\n",
    " - Top level Domain 이 자주 쓰이는 Domain인가?\n",
    " - 등록후 지난 일수\n",
    " - http:// or https://\n",
    " - #of http:// or https://\n",
    " - 특수문자(#, =, /,&)\n",
    " - com 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['length'] = df.url.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sharp'] = (df.url.str.count('#'))\n",
    "df['equal'] = (df.url.str.count('='))\n",
    "df['slash'] = ((df.url.str.count('/')) - 2)\n",
    "df['dbleslash'] = (df.url.str.count('//')) - 1\n",
    "df['question'] = (df.url.str.count('\\?'))\n",
    "df['com'] = (df.url.str.count('.com'))\n",
    "df['dot'] = (df.url.str.count('\\.'))\n",
    "df['protocols'] = (df.url.str.count('https://') + df.url.str.count('http://'))\n",
    "df['comma'] = (df.url.str.count('\\,'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb  = df.groupby(by = df.label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>sharp</th>\n",
       "      <th>equal</th>\n",
       "      <th>slash</th>\n",
       "      <th>dbleslash</th>\n",
       "      <th>question</th>\n",
       "      <th>com</th>\n",
       "      <th>dot</th>\n",
       "      <th>protocols</th>\n",
       "      <th>comma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.809978</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.052956</td>\n",
       "      <td>1.474444</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>2.337178</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>75.852041</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>3.084726</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.244283</td>\n",
       "      <td>0.750999</td>\n",
       "      <td>2.545049</td>\n",
       "      <td>1.011336</td>\n",
       "      <td>0.008977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label     length     sharp     equal     slash  dbleslash  question  \\\n",
       "label                                                                        \n",
       "0        0.0  35.809978  0.000978  0.052956  1.474444   0.000689  0.034044   \n",
       "1        1.0  75.852041  0.008322  0.535548  3.084726   0.016185  0.244283   \n",
       "\n",
       "            com       dot  protocols     comma  \n",
       "label                                           \n",
       "0      0.678333  2.337178   0.999622  0.000000  \n",
       "1      0.750999  2.545049   1.011336  0.008977  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(df.drop(columns = ['url','label']), df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'label', 'length', 'sharp', 'equal', 'slash', 'dbleslash',\n",
       "       'question', 'com', 'dot', 'protocols', 'comma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4348016  0.02832716 0.03409005 0.07396687 0.04464323 0.02885386\n",
      " 0.08180476 0.23030968 0.02994067 0.01326214]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Level Domain / Sub Domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tld = df.url.str.rpartition('.')[2]\n",
    "tld = tld.str.replace('\\/','')\n",
    "subdomain = df.url.str.rpartition('.')[0]\n",
    "subdomain = subdomain.str.rpartition('.')[2].str.replace('http://','').replace('https://','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.url.str.split(r'[/|.]').apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60261, 10000), (60261, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase = 'False', max_features = 10000, \n",
    "                             token_pattern = '(([\\w!@#$%^&*\\(\\)_\\+\\-\\={}\\|[\\]:\";\\'<>?,./])+)' )\n",
    "X = vectorizer.fit(words)\n",
    "feat = X.get_feature_names()\n",
    "X = vectorizer.transform(words)\n",
    "X.shape, df.drop(columns = ['url','label']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 23), match='!@#$%^||||+_)AACVBscfsf'>\n"
     ]
    }
   ],
   "source": [
    "a = '!@#$%^||||+_)AACVBscfsf'\n",
    "b = re.match('(([\\w!@#$%^&*\\(\\)_\\+\\-\\={}\\|[\\]:\";\\'<>?,./])+)', a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.hstack([df.drop(columns = ['url','label']), X]).tocsr()\n",
    "y_train = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 22,\n",
       " 26,\n",
       " 35,\n",
       " 55,\n",
       " 65,\n",
       " 70,\n",
       " 77,\n",
       " 91,\n",
       " 110,\n",
       " 130,\n",
       " 143,\n",
       " 154,\n",
       " 182,\n",
       " 286,\n",
       " 385,\n",
       " 455,\n",
       " 715,\n",
       " 770,\n",
       " 910,\n",
       " 1001,\n",
       " 1430,\n",
       " 2002,\n",
       " 5005,\n",
       " 10010)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1,2,5,7,10,11,13,14,22,26,35,55,65,70,77,91,110,130,143,154,182,286,385,455,715,770,910,1001,1430,2002,5005,10010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 10010)             0         \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 110, 91, 1)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_60 (TimeDis (None, 110, 91, 20)       60        \n",
      "_________________________________________________________________\n",
      "time_distributed_61 (TimeDis (None, 110, 45, 20)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, 110, 900)          0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 110, 900)          0         \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 110, 128)          395136    \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 498,078\n",
      "Trainable params: 498,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "c_input = tf.keras.Input(shape=(X_train.shape[1:]))\n",
    "H = tf.keras.layers.Reshape((110, int(X_train.shape[1]/110), 1))(c_input)\n",
    "#H = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=20, kernel_size=(2), padding='same', activation='tanh'))(H)\n",
    "#H = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2))(H)\n",
    "#H = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=20, kernel_size=(2), padding='same', activation='tanh'))(H)\n",
    "#H = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2))(H)\n",
    "H = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=20, kernel_size=(2), padding='same', activation='tanh'))(H)\n",
    "H = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2))(H)\n",
    "H = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(H)\n",
    "H = tf.keras.layers.Dropout(0.5)(H)\n",
    "#H CuDNNGRU(256, recurrent_dropout=0.5, unroll=True, return_sequences=True)(H)\n",
    "#H = GRU(256, recurrent_dropout=0.5, unroll=True, return_sequences=False, go_backwards=True)(H)\n",
    "H = tf.keras.layers.GRU(128, return_sequences=True)(H)\n",
    "H = tf.keras.layers.GRU(128, return_sequences=False, go_backwards=True)(H)\n",
    "H = tf.keras.layers.Dropout(rate=0.5)(H)\n",
    "H = tf.keras.layers.Dense(32, activation='tanh')(H)\n",
    "c_output = tf.keras.layers.Dense(2, activation='softmax')(H)\n",
    "model_cnn_lstm = tf.keras.Model(c_input, c_output)\n",
    "model_cnn_lstm.summary()\n",
    "# model_cnn_lstm = multi_gpu_model(model_cnn_lstm, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_input, mode='loss', val_mode=True, title='Entropy'):\n",
    "    history = model_input.history\n",
    "    if(val_mode):\n",
    "        plt.plot(history.history[mode])\n",
    "        plt.plot(history.history['val_'+mode])\n",
    "        plt.title(title)\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(history.history[mode])\n",
    "        plt.title(title)\n",
    "        plt.legend(['train'], loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_confusion_matrix(modelInput, feature, label, class_list=[\"first\", \"second\"], normalize=False, fig_size=(5,5)):\n",
    "    pred = modelInput.predict(feature)\n",
    "    cnf_matrix = confusion_matrix(np.argmax(label, axis=1), np.argmax(pred, axis=1))\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=fig_size) \n",
    "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xticks(np.arange(len(class_list)), class_list, rotation=45)\n",
    "    plt.yticks(np.arange(len(class_list)), class_list)\n",
    "    if(normalize):\n",
    "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cnf_matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cnf_matrix[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "def plot_history(model_input, mode='loss', val_mode=True, title='Entropy'):\n",
    "    history = model_input.history\n",
    "    if(val_mode):\n",
    "        plt.plot(history.history[mode])\n",
    "        plt.plot(history.history['val_'+mode])\n",
    "        plt.title(title)\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(history.history[mode])\n",
    "        plt.title(title)\n",
    "        plt.legend(['train'], loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48208 samples, validate on 12053 samples\n",
      "Epoch 1/50\n",
      " - 705s - loss: 0.3909 - acc: 0.8376 - val_loss: 0.3655 - val_acc: 0.8535\n",
      "Epoch 2/50\n",
      " - 689s - loss: 0.3903 - acc: 0.8369 - val_loss: 0.3632 - val_acc: 0.8554\n",
      "Epoch 3/50\n",
      " - 700s - loss: 0.3894 - acc: 0.8388 - val_loss: 0.3625 - val_acc: 0.8554\n",
      "Epoch 4/50\n",
      " - 707s - loss: 0.3901 - acc: 0.8378 - val_loss: 0.3597 - val_acc: 0.8572\n",
      "Epoch 5/50\n",
      " - 719s - loss: 0.3882 - acc: 0.8380 - val_loss: 0.3588 - val_acc: 0.8576\n",
      "Epoch 6/50\n",
      " - 715s - loss: 0.3860 - acc: 0.8389 - val_loss: 0.3585 - val_acc: 0.8573\n",
      "Epoch 7/50\n",
      " - 706s - loss: 0.3855 - acc: 0.8396 - val_loss: 0.3606 - val_acc: 0.8545\n",
      "Epoch 8/50\n",
      " - 703s - loss: 0.3831 - acc: 0.8414 - val_loss: 0.3566 - val_acc: 0.8577\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adam = tf.keras.optimizers.Adam(lr = 1e-04)\n",
    "# es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=5, mode='auto', restore_best_weights=True)\n",
    "# model_cnn_lstm.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "# history = model_cnn_lstm.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=500, verbose=2, shuffle=True, callbacks=[es])\n",
    "# plot_history(model_cnn_lstm, mode='loss', title='Categorical Crossentropy')\n",
    "# plot_history(model_cnn_lstm, mode='acc', title='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
