{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymEk-woRVIAT"
   },
   "source": [
    "# Build CNN For Comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3348,
     "status": "ok",
     "timestamp": 1582015315822,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "eghAwvsyQVz_",
    "outputId": "89cb5682-4722-4fdb-a82b-81ff1e271201"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Copyright 2019, Seokjun Bu, Softcomputing LAB all rights reserved.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Conv2D, Dense, MaxPool2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19178,
     "status": "ok",
     "timestamp": 1582015335758,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "Qal0l12VQ4hs",
    "outputId": "7c91cd83-c57e-4169-dd8c-5704ae8fc459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Fi9L2q3Q62K"
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/My Drive/test_colab/dataset_2_char_cat_45000_15000_140.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6555,
     "status": "ok",
     "timestamp": 1582015628053,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "iIsKMKpfRDkl",
    "outputId": "46f0ead9-6d1b-44b0-886a-3a7b75ff748f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 14000) (42000,)\n",
      "(18000, 14000) (18000,)\n"
     ]
    }
   ],
   "source": [
    "# Train, Test Split\n",
    "X, Y = data[:, 1:], data[:, 0]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, shuffle=True, random_state=11)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPGR2YzOSgOU"
   },
   "outputs": [],
   "source": [
    "Y_train_cnn, Y_test_cnn = to_categorical(Y_train), to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1289,
     "status": "ok",
     "timestamp": 1582015633073,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "VRMZ5R_HUWLE",
    "outputId": "2a6c2ea8-fdf8-45ae-f04f-a157d34ea0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14000)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 100, 140, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 140, 32)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 70, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 56000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 224004    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 232,430\n",
      "Trainable params: 232,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_input = Input((X_train.shape[1],))\n",
    "H = Reshape((100, 140, 1))(cnn_input)\n",
    "\n",
    "H = Conv2D(filters=32, kernel_size=(2,2), padding=\"same\", activation='relu')(H)\n",
    "H = MaxPool2D((2, 2))(H)\n",
    "\n",
    "H = Conv2D(filters=64, kernel_size=(2,2), padding=\"same\", activation='relu')(H)\n",
    "H = MaxPool2D((2, 2))(H)\n",
    "\n",
    "H = Flatten()(H)\n",
    "H = Dense(4, activation='relu')(H)\n",
    "\n",
    "cnn_output = Dense(2, activation = 'softmax')(H)\n",
    "cnn_model = Model(cnn_input, cnn_output)\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553179,
     "status": "ok",
     "timestamp": 1582016195256,
     "user": {
      "displayName": "jisu",
      "photoUrl": "",
      "userId": "07451387493531712306"
     },
     "user_tz": -540
    },
    "id": "vj4bldbmWHX1",
    "outputId": "c51aa57e-0acb-483a-dc2d-4b60ffa3d852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "33600/33600 [==============================] - 23s 674us/step - loss: 0.4620 - acc: 0.8224 - val_loss: 0.3405 - val_acc: 0.8543\n",
      "Epoch 2/500\n",
      "33600/33600 [==============================] - 8s 230us/step - loss: 0.3005 - acc: 0.8699 - val_loss: 0.2664 - val_acc: 0.8912\n",
      "Epoch 3/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.2513 - acc: 0.8929 - val_loss: 0.2390 - val_acc: 0.8998\n",
      "Epoch 4/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.2273 - acc: 0.9044 - val_loss: 0.2227 - val_acc: 0.9086\n",
      "Epoch 5/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.2117 - acc: 0.9128 - val_loss: 0.2096 - val_acc: 0.9155\n",
      "Epoch 6/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.2027 - acc: 0.9166 - val_loss: 0.2065 - val_acc: 0.9149\n",
      "Epoch 7/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1932 - acc: 0.9217 - val_loss: 0.1955 - val_acc: 0.9213\n",
      "Epoch 8/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1870 - acc: 0.9254 - val_loss: 0.1949 - val_acc: 0.9240\n",
      "Epoch 9/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1817 - acc: 0.9280 - val_loss: 0.1877 - val_acc: 0.9245\n",
      "Epoch 10/500\n",
      "33600/33600 [==============================] - 8s 230us/step - loss: 0.1780 - acc: 0.9293 - val_loss: 0.1850 - val_acc: 0.9243\n",
      "Epoch 11/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1734 - acc: 0.9321 - val_loss: 0.1838 - val_acc: 0.9244\n",
      "Epoch 12/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1702 - acc: 0.9338 - val_loss: 0.1804 - val_acc: 0.9267\n",
      "Epoch 13/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1671 - acc: 0.9338 - val_loss: 0.1775 - val_acc: 0.9286\n",
      "Epoch 14/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1637 - acc: 0.9363 - val_loss: 0.1761 - val_acc: 0.9304\n",
      "Epoch 15/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1619 - acc: 0.9373 - val_loss: 0.1746 - val_acc: 0.9289\n",
      "Epoch 16/500\n",
      "33600/33600 [==============================] - 8s 230us/step - loss: 0.1598 - acc: 0.9385 - val_loss: 0.1750 - val_acc: 0.9294\n",
      "Epoch 17/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1578 - acc: 0.9385 - val_loss: 0.1747 - val_acc: 0.9290\n",
      "Epoch 18/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1553 - acc: 0.9394 - val_loss: 0.1739 - val_acc: 0.9293\n",
      "Epoch 19/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1533 - acc: 0.9413 - val_loss: 0.1705 - val_acc: 0.9311\n",
      "Epoch 20/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1527 - acc: 0.9411 - val_loss: 0.1701 - val_acc: 0.9315\n",
      "Epoch 21/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1500 - acc: 0.9416 - val_loss: 0.1730 - val_acc: 0.9324\n",
      "Epoch 22/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1481 - acc: 0.9444 - val_loss: 0.1728 - val_acc: 0.9325\n",
      "Epoch 23/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1465 - acc: 0.9444 - val_loss: 0.1678 - val_acc: 0.9326\n",
      "Epoch 24/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1454 - acc: 0.9456 - val_loss: 0.1675 - val_acc: 0.9340\n",
      "Epoch 25/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1451 - acc: 0.9454 - val_loss: 0.1705 - val_acc: 0.9315\n",
      "Epoch 26/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1428 - acc: 0.9458 - val_loss: 0.1674 - val_acc: 0.9357\n",
      "Epoch 27/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1410 - acc: 0.9469 - val_loss: 0.1665 - val_acc: 0.9346\n",
      "Epoch 28/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1400 - acc: 0.9470 - val_loss: 0.1711 - val_acc: 0.9329\n",
      "Epoch 29/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1396 - acc: 0.9466 - val_loss: 0.1649 - val_acc: 0.9364\n",
      "Epoch 30/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1380 - acc: 0.9483 - val_loss: 0.1659 - val_acc: 0.9354\n",
      "Epoch 31/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1369 - acc: 0.9481 - val_loss: 0.1649 - val_acc: 0.9356\n",
      "Epoch 32/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1357 - acc: 0.9503 - val_loss: 0.1650 - val_acc: 0.9371\n",
      "Epoch 33/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1343 - acc: 0.9503 - val_loss: 0.1696 - val_acc: 0.9362\n",
      "Epoch 34/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1359 - acc: 0.9496 - val_loss: 0.1635 - val_acc: 0.9373\n",
      "Epoch 35/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1332 - acc: 0.9501 - val_loss: 0.1651 - val_acc: 0.9367\n",
      "Epoch 36/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1324 - acc: 0.9507 - val_loss: 0.1629 - val_acc: 0.9387\n",
      "Epoch 37/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1306 - acc: 0.9517 - val_loss: 0.1644 - val_acc: 0.9376\n",
      "Epoch 38/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1296 - acc: 0.9522 - val_loss: 0.1645 - val_acc: 0.9367\n",
      "Epoch 39/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1291 - acc: 0.9527 - val_loss: 0.1635 - val_acc: 0.9390\n",
      "Epoch 40/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1279 - acc: 0.9522 - val_loss: 0.1620 - val_acc: 0.9394\n",
      "Epoch 41/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1276 - acc: 0.9524 - val_loss: 0.1622 - val_acc: 0.9393\n",
      "Epoch 42/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1263 - acc: 0.9530 - val_loss: 0.1628 - val_acc: 0.9402\n",
      "Epoch 43/500\n",
      "33600/33600 [==============================] - 8s 230us/step - loss: 0.1257 - acc: 0.9538 - val_loss: 0.1625 - val_acc: 0.9380\n",
      "Epoch 44/500\n",
      "33600/33600 [==============================] - 8s 230us/step - loss: 0.1253 - acc: 0.9539 - val_loss: 0.1627 - val_acc: 0.9390\n",
      "Epoch 45/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1245 - acc: 0.9534 - val_loss: 0.1697 - val_acc: 0.9319\n",
      "Epoch 46/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1239 - acc: 0.9540 - val_loss: 0.1615 - val_acc: 0.9400\n",
      "Epoch 47/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1224 - acc: 0.9541 - val_loss: 0.1630 - val_acc: 0.9377\n",
      "Epoch 48/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1217 - acc: 0.9550 - val_loss: 0.1624 - val_acc: 0.9402\n",
      "Epoch 49/500\n",
      "33600/33600 [==============================] - 8s 231us/step - loss: 0.1215 - acc: 0.9546 - val_loss: 0.1612 - val_acc: 0.9407\n",
      "Epoch 50/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1200 - acc: 0.9551 - val_loss: 0.1647 - val_acc: 0.9367\n",
      "Epoch 51/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1201 - acc: 0.9555 - val_loss: 0.1615 - val_acc: 0.9407\n",
      "Epoch 52/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1190 - acc: 0.9563 - val_loss: 0.1619 - val_acc: 0.9393\n",
      "Epoch 53/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1177 - acc: 0.9567 - val_loss: 0.1634 - val_acc: 0.9387\n",
      "Epoch 54/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1181 - acc: 0.9559 - val_loss: 0.1641 - val_acc: 0.9365\n",
      "Epoch 55/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1175 - acc: 0.9568 - val_loss: 0.1628 - val_acc: 0.9383\n",
      "Epoch 56/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1161 - acc: 0.9571 - val_loss: 0.1608 - val_acc: 0.9396\n",
      "Epoch 57/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1172 - acc: 0.9567 - val_loss: 0.1606 - val_acc: 0.9394\n",
      "Epoch 58/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1144 - acc: 0.9579 - val_loss: 0.1613 - val_acc: 0.9400\n",
      "Epoch 59/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1144 - acc: 0.9576 - val_loss: 0.1628 - val_acc: 0.9392\n",
      "Epoch 60/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1131 - acc: 0.9584 - val_loss: 0.1605 - val_acc: 0.9399\n",
      "Epoch 61/500\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1126 - acc: 0.9587 - val_loss: 0.1611 - val_acc: 0.9399\n",
      "Epoch 62/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1122 - acc: 0.9586 - val_loss: 0.1607 - val_acc: 0.9400\n",
      "Epoch 63/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1116 - acc: 0.9594 - val_loss: 0.1624 - val_acc: 0.9399\n",
      "Epoch 64/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1113 - acc: 0.9587 - val_loss: 0.1608 - val_acc: 0.9402\n",
      "Epoch 65/500\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.1102 - acc: 0.9593 - val_loss: 0.1611 - val_acc: 0.9400\n",
      "Epoch 66/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1121 - acc: 0.9584 - val_loss: 0.1673 - val_acc: 0.9374\n",
      "Epoch 67/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1095 - acc: 0.9594 - val_loss: 0.1609 - val_acc: 0.9395\n",
      "Epoch 68/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1082 - acc: 0.9602 - val_loss: 0.1654 - val_acc: 0.9381\n",
      "Epoch 69/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1081 - acc: 0.9598 - val_loss: 0.1619 - val_acc: 0.9396\n",
      "Epoch 70/500\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.1074 - acc: 0.9610 - val_loss: 0.1626 - val_acc: 0.9402\n",
      "CPU times: user 5min 29s, sys: 1min 38s, total: 7min 7s\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "adam = Adam(lr = 1e-04)\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=10, restore_best_weights=True)\n",
    "history = cnn_model.fit(X_train, Y_train_cnn, validation_split=0.2, \n",
    "                        epochs=500, batch_size=512, shuffle=True, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1LMEde9Xllp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPcThzk2ErMhIhxsyYrRzbJ",
   "machine_shape": "hm",
   "name": "Build CNN.ipynb ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
